{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7iWFeYKELmun3L9LHavV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elemnurguner/data-ai-projects/blob/main/Dondurulmu%C5%9FG%C4%B1dalar%C4%B1nSonKullanmaTahmini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m89xnMQ1NinV",
        "outputId": "da693125-f373-4572-a1cd-c21de399c94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Gıda_Türü Paketleme_Türü   Sıcaklık        Nem        pH  Mikrobiyal_Yük  \\\n",
            "0     Balık         Karton -23.325174  75.476720  5.944954            8850   \n",
            "1     Tavuk         Karton -23.954322  70.918034  4.222316            7454   \n",
            "2     Meyve         Karton -18.635698  72.700644  5.126407            4616   \n",
            "3     Tavuk         Karton -17.935243  78.471516  6.411444            3722   \n",
            "4     Tavuk         Karton -24.684139  90.064642  5.300417            4499   \n",
            "\n",
            "     Raf_Ömrü  \n",
            "0  320.449681  \n",
            "1  401.497660  \n",
            "2  346.003484  \n",
            "3  297.846086  \n",
            "4  367.709601  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Rastgele veri oluşturmak için seed belirleme\n",
        "np.random.seed(42)\n",
        "\n",
        "# Veri seti boyutu\n",
        "num_samples = 1000\n",
        "\n",
        "# Gıda türleri\n",
        "food_types = ['Et', 'Sebze', 'Meyve', 'Balık', 'Tavuk']\n",
        "\n",
        "# Paketleme türleri\n",
        "packaging_types = ['Vakum', 'Plastik', 'Kağıt', 'Karton']\n",
        "\n",
        "# Rastgele veri oluşturma\n",
        "data = {\n",
        "    'Gıda_Türü': np.random.choice(food_types, num_samples),\n",
        "    'Paketleme_Türü': np.random.choice(packaging_types, num_samples),\n",
        "    'Sıcaklık': np.random.uniform(-25, -15, num_samples),  # Dondurucu sıcaklık\n",
        "    'Nem': np.random.uniform(70, 95, num_samples),        # Nem oranı\n",
        "    'pH': np.random.uniform(4.0, 7.0, num_samples),       # pH değeri\n",
        "    'Mikrobiyal_Yük': np.random.randint(100, 10000, num_samples),  # Mikrobiyal yük\n",
        "}\n",
        "\n",
        "# Raf ömrü hesaplama (örnek bir formül)\n",
        "# Bu formül, sıcaklık, nem, pH ve mikrobiyal yüke bağlı olarak raf ömrünü tahmin eder.\n",
        "data['Raf_Ömrü'] = (\n",
        "    365  # Temel raf ömrü (gün)\n",
        "    - (data['Sıcaklık'] + 20) * 10  # Sıcaklık etkisi\n",
        "    - (data['Nem'] - 80) * 2        # Nem etkisi\n",
        "    - (data['pH'] - 6.0) * 30       # pH etkisi\n",
        "    - data['Mikrobiyal_Yük'] / 100  # Mikrobiyal yük etkisi\n",
        ")\n",
        "\n",
        "# Veriyi DataFrame'e dönüştürme\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Raf ömrünü pozitif yapma (negatif değerleri düzeltme)\n",
        "df['Raf_Ömrü'] = df['Raf_Ömrü'].apply(lambda x: max(x, 30))  # Minimum 30 gün\n",
        "\n",
        "# Veri setini göster\n",
        "print(df.head())\n",
        "\n",
        "# Veri setini CSV olarak kaydetme\n",
        "df.to_csv('dondurulmus_gida_veri_seti.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "burda kendi veri setimizi kendimiz oluşturduk ."
      ],
      "metadata": {
        "id": "Ar4u7J8sNvVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Veri setini yükleme\n",
        "df = pd.read_csv('dondurulmus_gida_veri_seti.csv')\n",
        "\n",
        "# İlk 5 satırı göster\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQ4wcr9N7JS",
        "outputId": "bdc0b806-e4b8-45c6-b19a-c3a6da4a6970"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Gıda_Türü Paketleme_Türü   Sıcaklık        Nem        pH  Mikrobiyal_Yük  \\\n",
            "0     Balık         Karton -23.325174  75.476720  5.944954            8850   \n",
            "1     Tavuk         Karton -23.954322  70.918034  4.222316            7454   \n",
            "2     Meyve         Karton -18.635698  72.700644  5.126407            4616   \n",
            "3     Tavuk         Karton -17.935243  78.471516  6.411444            3722   \n",
            "4     Tavuk         Karton -24.684139  90.064642  5.300417            4499   \n",
            "\n",
            "     Raf_Ömrü  \n",
            "0  320.449681  \n",
            "1  401.497660  \n",
            "2  346.003484  \n",
            "3  297.846086  \n",
            "4  367.709601  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Veri Ön İşleme\n",
        "Veri setindeki kategorik değişkenleri (örneğin, Gıda_Türü ve Paketleme_Türü) sayısallaştıralım ve sayısal değişkenleri normalize edelim."
      ],
      "metadata": {
        "id": "QWrscdE1N_DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Özellikler ve hedef değişken\n",
        "X = df.drop('Raf_Ömrü', axis=1)  # Özellikler\n",
        "y = df['Raf_Ömrü']               # Hedef değişken\n",
        "\n",
        "# Kategorik ve sayısal özellikleri ayırma\n",
        "categorical_features = ['Gıda_Türü', 'Paketleme_Türü']\n",
        "numerical_features = ['Sıcaklık', 'Nem', 'pH', 'Mikrobiyal_Yük']\n",
        "\n",
        "# Ön işleme adımları\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_features),  # Kategorik özellikleri one-hot encoding\n",
        "        ('num', StandardScaler(), numerical_features)    # Sayısal özellikleri standartlaştırma\n",
        "    ])\n",
        "\n",
        "# Veriyi ön işleme\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# İşlenmiş veriyi kontrol etme\n",
        "print(X_processed[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adn1EjIgN_xq",
        "outputId": "786e8741-a6c3-4777-a435-710d440b3cfb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.         -1.16638273 -0.95377374  0.54310617\n",
            "   1.34414585]\n",
            " [ 0.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.         -1.38467554 -1.58522499 -1.46783208\n",
            "   0.85538247]\n",
            " [ 0.          0.          1.          0.          0.          1.\n",
            "   0.          0.          0.          0.46070656 -1.3383049  -0.41243306\n",
            "  -0.13824966]\n",
            " [ 0.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          0.70374059 -0.53894639  1.08766744\n",
            "  -0.45125429]\n",
            " [ 0.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.         -1.63789726  1.06688774 -0.20930086\n",
            "  -0.17921335]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Veriyi Eğitim ve Test Setlerine Ayırma\n",
        "Veri setini eğitim ve test setlerine ayıralım."
      ],
      "metadata": {
        "id": "GtlRuCw6OGJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Eğitim seti boyutu: {X_train.shape}\")\n",
        "print(f\"Test seti boyutu: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4otfLjkVOHsZ",
        "outputId": "bb0fb30e-4e6b-4ff3-9ae8-b25993bd7575"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim seti boyutu: (800, 13)\n",
            "Test seti boyutu: (200, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Eğitimi\n",
        "Bu örnekte, bir Random Forest Regresyon modeli kullanacağız."
      ],
      "metadata": {
        "id": "Ug0tiVVkOLdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Model oluşturma\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Modeli eğitme\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Eğitim seti üzerinde tahmin yapma\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "6j_1iHsNOMO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Performansını Değerlendirme\n",
        "Modelin performansını değerlendirmek için Ortalama Kare Hatası (MSE) ve R² Skoru kullanacağız."
      ],
      "metadata": {
        "id": "PavtpKGpORwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Eğitim seti performansı\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Test seti performansı\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Eğitim Seti MSE: {train_mse}\")\n",
        "print(f\"Eğitim Seti R²: {train_r2}\")\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tCRawceOS9i",
        "outputId": "07c748c0-2a0d-45bb-c70c-e96a361daac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim Seti MSE: 14.627210763642074\n",
            "Eğitim Seti R²: 0.9940854373183682\n",
            "Test Seti MSE: 97.4374878212823\n",
            "Test Seti R²: 0.9680912952437766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Tahmin Yapma\n",
        "Eğitilen modeli kullanarak yeni veriler üzerinde tahmin yapalım."
      ],
      "metadata": {
        "id": "rnbi2e80OXMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yeni bir örnek veri\n",
        "new_data = pd.DataFrame({\n",
        "    'Gıda_Türü': ['Et'],\n",
        "    'Paketleme_Türü': ['Vakum'],\n",
        "    'Sıcaklık': [-18],\n",
        "    'Nem': [85],\n",
        "    'pH': [6.5],\n",
        "    'Mikrobiyal_Yük': [1000]\n",
        "})\n",
        "\n",
        "# Veriyi ön işleme\n",
        "new_data_processed = preprocessor.transform(new_data)\n",
        "\n",
        "# Tahmin yapma\n",
        "predicted_shelf_life = model.predict(new_data_processed)\n",
        "print(f\"Tahmini Raf Ömrü: {predicted_shelf_life[0]:.2f} gün\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFI-O8JAOYYb",
        "outputId": "8bd65ced-9ab6-4f3a-f7cc-55aa8473ae2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmini Raf Ömrü: 311.24 gün\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Modeli Geliştirme\n",
        "Modelin performansını artırmak için şu adımları deneyebilirsiniz:\n",
        "\n",
        "Hiperparametre Optimizasyonu: GridSearchCV veya RandomizedSearchCV kullanarak en iyi hiperparametreleri bulun.\n",
        "\n",
        "Farklı Modeller Deneyin: Gradient Boosting, XGBoost veya derin öğrenme modelleri kullanın.\n",
        "\n",
        "Daha Fazla Veri Toplayın: Veri setinizi genişleterek modelin doğruluğunu artırın."
      ],
      "metadata": {
        "id": "SZOBuaR7OiyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hiperparametre Optimizasyonu\n",
        "Hiperparametre optimizasyonu, modelin en iyi performansı göstermesi için en uygun hiperparametreleri bulma işlemidir. Bunun için GridSearchCV veya RandomizedSearchCV kullanabilirsiniz.\n",
        "\n",
        "GridSearchCV ile Hiperparametre Optimizasyonu"
      ],
      "metadata": {
        "id": "_jeoCLHjO1bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hiperparametre grid'i\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# GridSearchCV ile model oluşturma\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # 5 katlı çapraz doğrulama\n",
        "    scoring='neg_mean_squared_error',  # MSE'yi minimize et\n",
        "    n_jobs=-1  # Tüm CPU çekirdeklerini kullan\n",
        ")\n",
        "\n",
        "# GridSearchCV'yi eğitme\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# En iyi hiperparametreler\n",
        "print(\"En iyi hiperparametreler:\", grid_search.best_params_)\n",
        "\n",
        "# En iyi model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Performans değerlendirme\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ReiGk2ROmQp",
        "outputId": "93aa5741-bbd0-4262-fc9c-07d80985fd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi hiperparametreler: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Test Seti MSE: 96.80903689115166\n",
            "Test Seti R²: 0.9682970995561794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomizedSearchCV ile Hiperparametre Optimizasyonu"
      ],
      "metadata": {
        "id": "K0Cig22uPAJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Hiperparametre dağılımları\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 4)\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV ile model oluşturma\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # Denenecek kombinasyon sayısı\n",
        "    cv=5,  # 5 katlı çapraz doğrulama\n",
        "    scoring='neg_mean_squared_error',  # MSE'yi minimize et\n",
        "    n_jobs=-1  # Tüm CPU çekirdeklerini kullan\n",
        ")\n",
        "\n",
        "# RandomizedSearchCV'yi eğitme\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# En iyi hiperparametreler\n",
        "print(\"En iyi hiperparametreler:\", random_search.best_params_)\n",
        "\n",
        "# En iyi model\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Performans değerlendirme\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPJVYXWZPBs9",
        "outputId": "c02448bf-c81e-4ca0-b731-67726e5b8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi hiperparametreler: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 185}\n",
            "Test Seti MSE: 98.68444402767363\n",
            "Test Seti R²: 0.9676829436090684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Farklı Modeller Deneyin\n",
        "Random Forest dışında farklı modeller de deneyebilirsiniz. Örneğin, Gradient Boosting veya XGBoost gibi gelişmiş modeller kullanabilirsiniz.\n",
        "\n",
        "Gradient Boosting Regresyon"
      ],
      "metadata": {
        "id": "XBNAbD5VPFN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Gradient Boosting modeli\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Modeli eğitme\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Performans değerlendirme\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEUjV34IPGSk",
        "outputId": "4b94ea6a-e6d8-4369-ff60-cb9eaf1d1d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Seti MSE: 41.653042115273884\n",
            "Test Seti R²: 0.9863595146716774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Regresyon"
      ],
      "metadata": {
        "id": "BaUQAKoqPIJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# XGBoost modeli\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Modeli eğitme\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Performans değerlendirme\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnoIleZmPJiU",
        "outputId": "a20ba31e-e774-414d-ff9a-9b76521cae41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Seti MSE: 89.73732868004227\n",
            "Test Seti R²: 0.970612933579367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Derin Öğrenme Modelleri Deneyin\n",
        "Daha karmaşık modeller için derin öğrenme kullanabilirsiniz. Örneğin, bir sinir ağı (neural network) modeli eğitebilirsiniz.\n",
        "\n",
        "Basit Bir Sinir Ağı Modeli"
      ],
      "metadata": {
        "id": "nOjeU5fBPOUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sinir ağı modeli\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Giriş katmanı\n",
        "model.add(Dense(32, activation='relu'))  # Gizli katman\n",
        "model.add(Dense(1))  # Çıkış katmanı\n",
        "\n",
        "# Modeli derleme\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Modeli eğitme\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "y_test_pred = model.predict(X_test).flatten()\n",
        "\n",
        "# Performans değerlendirme\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test Seti MSE: {test_mse}\")\n",
        "print(f\"Test Seti R²: {test_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLp7acA1PPlF",
        "outputId": "748e4c64-861b-4659-d7c3-28f7454dde60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 107809.2344 - val_loss: 104936.1484\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 107640.0781 - val_loss: 103320.0234\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 105972.3359 - val_loss: 100432.7109\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101860.9531 - val_loss: 95601.8359\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 97128.3125 - val_loss: 88141.7734\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 88320.1016 - val_loss: 77616.1172\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 76804.5391 - val_loss: 64073.5430\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 60659.3203 - val_loss: 48342.9883\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46135.7109 - val_loss: 32164.7812\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29369.4961 - val_loss: 18004.9219\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15710.1377 - val_loss: 7988.0454\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6434.2222 - val_loss: 2644.5806\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1977.7792 - val_loss: 671.8880\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 442.5506 - val_loss: 202.2023\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 133.3578 - val_loss: 117.9386\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 90.3139 - val_loss: 94.1467\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 75.5149 - val_loss: 80.4128\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 66.3737 - val_loss: 71.0646\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 59.7199 - val_loss: 64.5473\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 54.6919 - val_loss: 59.4362\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 46.2090 - val_loss: 55.2608\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.5478 - val_loss: 52.1208\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.6533 - val_loss: 49.1992\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.0437 - val_loss: 47.1770\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.1597 - val_loss: 45.1684\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.2109 - val_loss: 43.5552\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.6534 - val_loss: 42.0057\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.9937 - val_loss: 40.6518\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.6864 - val_loss: 39.6845\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.8881 - val_loss: 38.7526\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3761 - val_loss: 37.7424\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.9349 - val_loss: 37.1263\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.5340 - val_loss: 36.3549\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6623 - val_loss: 35.5832\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4965 - val_loss: 35.1201\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.4248 - val_loss: 34.3573\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6754 - val_loss: 34.0340\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1801 - val_loss: 33.4439\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7090 - val_loss: 32.9004\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5763 - val_loss: 32.5331\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8338 - val_loss: 32.0039\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3035 - val_loss: 31.5154\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.4411 - val_loss: 30.9064\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2692 - val_loss: 30.4942\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1663 - val_loss: 30.1224\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.4429 - val_loss: 29.7162\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.6866 - val_loss: 29.3463\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.2696 - val_loss: 28.9882\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.0639 - val_loss: 28.4634\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.9412 - val_loss: 28.0205\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Test Seti MSE: 37.67992081049587\n",
            "Test Seti R²: 0.9876606273902991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Sonuçları Karşılaştırın\n",
        "Farklı modellerin performanslarını karşılaştırarak en iyi modeli seçin. Örneğin:\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "XGBoost\n",
        "\n",
        "Sinir Ağı\n",
        "\n",
        "Bu modellerin MSE ve R² değerlerini karşılaştırarak hangisinin daha iyi performans gösterdiğini belirleyebilirsiniz."
      ],
      "metadata": {
        "id": "bROWQibePSoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    explained_variance = explained_variance_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"{model_name} Performansı:\")\n",
        "    print(f\"MSE: {mse:.2f}\")\n",
        "    print(f\"RMSE: {rmse:.2f}\")\n",
        "    print(f\"MAE: {mae:.2f}\")\n",
        "    print(f\"R²: {r2:.2f}\")\n",
        "    print(f\"Açıklanmış Varyans: {explained_variance:.2f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --------------------------------------------\n",
        "# DÜZELTME: TÜM TAHMİN DEĞİŞKENLERİNİ TANIMLA\n",
        "# --------------------------------------------\n",
        "\n",
        "# Random Forest Tahminleri (DÜZELTME: y_test_pred_rf tanımlandı)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_test_pred_rf = rf_model.predict(X_test)  # Değişken adı düzeltildi ✅\n",
        "\n",
        "# Gradient Boosting Tahminleri (DÜZELTME: y_test_pred_gb tanımlandı)\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_test_pred_gb = gb_model.predict(X_test)  # Değişken adı düzeltildi ✅\n",
        "\n",
        "# XGBoost Tahminleri (DÜZELTME: y_test_pred_xgb tanımlandı)\n",
        "from xgboost import XGBRegressor\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_test_pred_xgb = xgb_model.predict(X_test)  # Değişken adı düzeltildi ✅\n",
        "\n",
        "# Sinir Ağı Tahminleri (DÜZELTME: y_test_pred_nn tanımlandı)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "nn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "nn_model.compile(optimizer='adam', loss='mse')\n",
        "nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "y_test_pred_nn = nn_model.predict(X_test).flatten()  # Değişken adı düzeltildi ✅\n",
        "\n",
        "# --------------------------------------------\n",
        "# PERFORMANS DEĞERLENDİRME (ARTIK HATA YOK)\n",
        "# --------------------------------------------\n",
        "evaluate_model(y_test, y_test_pred_rf, \"Random Forest\")\n",
        "evaluate_model(y_test, y_test_pred_gb, \"Gradient Boosting\")\n",
        "evaluate_model(y_test, y_test_pred_xgb, \"XGBoost\")\n",
        "evaluate_model(y_test, y_test_pred_nn, \"Sinir Ağı\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu50H3LMTXkq",
        "outputId": "567f5774-2f33-45c1-fff3-94d47b23b838"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Random Forest Performansı:\n",
            "MSE: 97.44\n",
            "RMSE: 9.87\n",
            "MAE: 7.83\n",
            "R²: 0.97\n",
            "Açıklanmış Varyans: 0.97\n",
            "------------------------------\n",
            "Gradient Boosting Performansı:\n",
            "MSE: 41.65\n",
            "RMSE: 6.45\n",
            "MAE: 5.14\n",
            "R²: 0.99\n",
            "Açıklanmış Varyans: 0.99\n",
            "------------------------------\n",
            "XGBoost Performansı:\n",
            "MSE: 89.74\n",
            "RMSE: 9.47\n",
            "MAE: 7.68\n",
            "R²: 0.97\n",
            "Açıklanmış Varyans: 0.97\n",
            "------------------------------\n",
            "Sinir Ağı Performansı:\n",
            "MSE: 22.90\n",
            "RMSE: 4.79\n",
            "MAE: 3.41\n",
            "R²: 0.99\n",
            "Açıklanmış Varyans: 0.99\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}