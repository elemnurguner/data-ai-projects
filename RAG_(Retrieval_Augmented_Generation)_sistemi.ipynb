{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGNNTc8zyVmEryODauRmuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elemnurguner/data-ai-projects/blob/main/RAG_(Retrieval_Augmented_Generation)_sistemi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v9k4y3gilTZy"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers  # RAG için temel kütüphaneler\n",
        "!pip install transformers  # Dil modelleri için"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community faiss-cpu sentence-transformers transformers"
      ],
      "metadata": {
        "id": "8Dm9osxwnNx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader  # Düzeltildi\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings  # Düzeltildi\n",
        "from langchain_community.vectorstores import FAISS  # Düzeltildi\n",
        "from transformers import pipeline\n",
        "\n",
        "# 1. Örnek Dokümanlar (TextLoader yerine direkt liste kullanıyoruz)\n",
        "documents = [\n",
        "    \"Ürün X'in kurulumu için en az 4 GB RAM gereklidir\",\n",
        "    \"Destek saatleri: Pazartesi-Cuma, 09:00-18:00.\",\n",
        "    \"Yazılım güncellemeleri otomatik olarak gece 02:00'da yüklenir.\"\n",
        "]\n",
        "# 2. Dokümanları Vektör Veritabanına Kaydet (Retrieval)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "vector_store = FAISS.from_texts(documents, embeddings)\n",
        "\n",
        "# 3. Kullanıcı Sorusuna Cevap Oluşturma (Generation)\n",
        "def rag_answer(question):\n",
        "    # A) En İlgili Dokümanı Bul\n",
        "    relevant_docs = vector_store.similarity_search(question, k=1)\n",
        "    context = relevant_docs[0].page_content\n",
        "\n",
        "    # B) Dil Modeli ile Cevap Üret\n",
        "    generator = pipeline(\"text-generation\", model=\"gpt2\")  # GPT-2 kullanıyoruz (basit bir örnek için)\n",
        "    answer = generator(\n",
        "        f\"Soru: {question}\\nBağlam: {context}\\nCevap:\",\n",
        "        max_length=100,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    return answer[0]['generated_text']\n",
        "\n",
        "# Test Edelim\n",
        "question = \"Ürün X'i kurarken RAM gereksinimi nedir?\"\n",
        "print(rag_answer(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hww36cUlgDQ",
        "outputId": "ed9dc10c-cd57-4d2a-c82c-11516bd71b2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soru: Ürün X'i kurarken RAM gereksinimi nedir?\n",
            "Bağlam: Ürün X'in kurulumu için en az 4 GB RAM gereklidir\n",
            "Cevap: No, that's for our sake [clementine sighed] Kallenka: No. I'll go out and take it with them.\n",
            "Kaçnak: We're not making an\n"
          ]
        }
      ]
    }
  ]
}