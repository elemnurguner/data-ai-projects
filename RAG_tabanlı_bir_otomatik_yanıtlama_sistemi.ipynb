{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbI1NEmP0NXs9bpW0uUvrt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elemnurguner/data-ai-projects/blob/main/RAG_tabanl%C4%B1_bir_otomatik_yan%C4%B1tlama_sistemi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_l4ruhcpPdq"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-community faiss-cpu sentence-transformers transformers gradio\n",
        "!pip install -q unstructured pdfminer.six  # PDF ve dosya desteği için"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 $(lsof -t -i :7860)  # Tüm meşgul portları kapat\n",
        "!kill -9 $(lsof -t -i :7861)\n",
        "!fuser -k 80/tcp"
      ],
      "metadata": {
        "id": "FdriAHs9w6LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers langchain-community faiss-cpu sentence-transformers gradio unstructured pdfminer.six\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import gradio as gr\n",
        "\n",
        "# 1. Dokümanları Oluşturma\n",
        "def initialize_documents():\n",
        "    if not os.path.exists(\"documents\"):\n",
        "        os.makedirs(\"documents\")\n",
        "        sample_text = \"\"\"Ürün X Özellikleri:\n",
        "        - Minimum 4 GB RAM\n",
        "        - Windows 11/10/8.1 desteği\n",
        "        - 64-bit işletim sistemi gereksinimi\n",
        "        - Güncellemeler her Perşembe 02:00'da\"\"\"\n",
        "        with open(\"documents/teknik_rehber.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(sample_text)\n",
        "\n",
        "# 2. Vektör Veritabanı\n",
        "def create_vector_database():\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "    )\n",
        "    loader = DirectoryLoader(\"documents\", glob=\"**/*.txt\")\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    vector_db = FAISS.from_documents(texts, embeddings)\n",
        "    vector_db.save_local(\"faiss_index\")\n",
        "\n",
        "# 3. Dil Modeli\n",
        "def initialize_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\")\n",
        "    generator = pipeline(\n",
        "        \"text2text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1,\n",
        "        max_length=200,\n",
        "        num_beams=4\n",
        "    )\n",
        "    return generator\n",
        "\n",
        "# 4. Doğrulama Sistemi\n",
        "def validate_response(answer: str) -> bool:\n",
        "    required_terms = [\"ram\", \"gb\", \"windows\", \"güncelleme\"]\n",
        "    return any(term in answer.lower() for term in required_terms)\n",
        "\n",
        "# 5. RAG Motoru\n",
        "def generate_answer(question: str) -> str:\n",
        "    try:\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "        )\n",
        "        vector_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "        relevant_docs = vector_db.similarity_search(question, k=2)\n",
        "        context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "        generator = initialize_model()\n",
        "        response = generator(\n",
        "            f\"Bağlam: {context}\\nSoru: {question}\\nCevap:\",\n",
        "            temperature=0.3\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        return response if validate_response(response) else \"❗ Bilgi bulunamadı.\"\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Hata: {str(e)}\"\n",
        "\n",
        "# 6. Arayüz\n",
        "def create_interface():\n",
        "    return gr.Interface(\n",
        "        fn=generate_answer,\n",
        "        inputs=gr.Textbox(label=\"Sorunuz\"),\n",
        "        outputs=gr.Textbox(label=\"Cevap\"),\n",
        "        examples=[\n",
        "            [\"Ürün için minimum RAM gereksinimi nedir?\"],\n",
        "            [\"Hangi Windows sürümleri desteklenir?\"]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# 7. Başlatma\n",
        "if __name__ == \"__main__\":\n",
        "    initialize_documents()\n",
        "    if not os.path.exists(\"faiss_index\"):\n",
        "        create_vector_database()\n",
        "    create_interface().launch(share=True)"
      ],
      "metadata": {
        "id": "kocEcLAEr2xW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}